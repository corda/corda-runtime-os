# Default Kafka properties. Settings in this file are used if no property is specified by the user. If no property is
# specified here, then the Kafka default is used. Note that some set defaults here are the same as those in the enforced
# configuration, as a precaution.

# Common defaults across all consumers and producers
common {
    # Default connection server. Note that this will need overriding in the majority of cases.
    bootstrap.servers = "localhost:9092"
}

# Defaults for all consumers.
consumer = ${common} {
    # This ensures a default where connection with no offset for a consumer group does not result in an exception.
    auto.offset.reset = earliest
    # Ensures that messages from uncommitted transactions are not visible. This is required to meet transactionality
    # requirements on patterns that need it.
    isolation.level = read_committed
    # Force consumers to commit their offsets manually. Again required for transactionality.
    enable.auto.commit = false
    # Retrieve 500 records maximum per poll. Note that poll will return immediately if any records are available, so a
    # batch may contain fewer than 500 records.
    max.poll.records = 200
    # Time to allow between polls on a consumer before a rebalance occurs that removes this consumer's partitions.
    max.poll.interval.ms = 300000
    # Timeout of heartbeats between the consumer and the broker. If no heartbeat is received in this timeframe, a
    # rebalance will occur.
    session.timeout.ms = 60000
    # Frequency of heartbeats between the consumer and the broker. Should be no higher than 1/3 of the session timeout.
    heartbeat.interval.ms = 20000
    # The maximum amount of time kafka broker will wait before answering a consumer request if there hasn't been
    # an update to the topic
    fetch.max.wait.ms = 500
}

# Defaults for all producers.
producer = ${common} {
    # Ensures that messages are sent to the broker exactly once. Note that some configuration settings must be set to
    # compatible values as a result of this. A ConfigException will be raised if these are set to incompatible values.
    enable.idempotence = true
    # Ensures that messages are not lost due to broker failure at inopportune moments. This forces acknowledgements from
    # all in-sync replicas before continuing, which ensures the message has reached at least one broker.
    acks = all
    # Ensure producers use compression when sending data
    compression.type = zstd
}

# Roles that particular consumers or producers could be taking. By tying consumers and producers to the roles they are
# performing in the patterns, each can be configured properly to reflect the job they are supposed to do.
roles {
    admin {
        admin = ${common}
    }
    pubsub {
        consumer = ${consumer} {
            # Pubsub consumers can ignore old messages so choose to start at the end of the stream.
            auto.offset.reset = latest
        }
    }
    compacted {
        consumer = ${consumer}
    }
    durable {
        consumer = ${consumer}
        # Producer sends a batch either when the batch is full or when the linger.ms limit is reached. The producer used
        # within this pattern is transactional by default, and the transaction commit also causes a flush.
        producer = ${producer} {
            # Maximum time to wait for additional messages before sending the current batch.
            linger.ms = 1000
            # Maximum amount of memory in bytes (not messages) that will be used for each batch. Can not be higher than
            # the value configured for "message.max.bytes" on the broker side (1mb by default).
            batch.size = 750000
        }
    }
    stateAndEvent {
        stateConsumer = ${consumer}
        eventConsumer = ${consumer}
        # Producer sends a batch either when the batch is full or when the linger.ms limit is reached. The producer used
        # within this pattern is transactional by default, and the transaction commit also causes a flush.
        producer = ${producer} {
            # Maximum time to wait for additional messages before sending the current batch.
            linger.ms = 5
            # Maximum amount of memory in bytes (not messages) that will be used for each batch. Can not be higher than
            # the value configured for "message.max.bytes" on the broker side (1mb by default).
            batch.size = 204800
        }
    }
    eventLog {
        consumer = ${consumer}
        # Producer sends a batch either when the batch is full or when the linger.ms limit is reached. The producer used
        # within this pattern is transactional by default, and the transaction commit also causes a flush.
        producer = ${producer} {
            # Maximum time to wait for additional messages before sending the current batch.
            linger.ms = 1000
            # Maximum amount of memory in bytes (not messages) that will be used for each batch. Can not be higher than
            # the value configured for "message.max.bytes" on the broker side (1mb by default).
            batch.size = 750000
        }
    }
    rpcSender {
        consumer = ${consumer} {
            # RPC pattern consumers can ignore old messages so choose to start at the end of the stream.
            auto.offset.reset=latest
        }
        producer = ${producer}
    }
    rpcResponder {
        consumer = ${consumer} {
            # RPC pattern consumers can ignore old messages so choose to start at the end of the stream.
            auto.offset.reset = latest
        }
        producer = ${producer}
    }
    publisher {
        producer = ${producer}
    }
}
