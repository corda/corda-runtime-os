
import groovy.transform.Field


@Field
String postgresHost = 'localhost'
@Field
String postgresPort = '5432'
@Field
String postgresCredentialsId = 'e2e-postgresql-credentials'
@Field
String postgresDb = "test_${UUID.randomUUID().toString().replace("-", "")}"


pipeline {
    agent {
        docker {
            image 'build-zulu-openjdk:11'
            label 'docker'
            registryUrl 'https://engineering-docker.software.r3.com/'
            registryCredentialsId 'artifactory-credentials'
            args '-v /tmp:/host_tmp '
            alwaysPull true
        }
    }

    environment {
        ARTIFACTORY_CREDENTIALS = credentials('artifactory-credentials')
        BUILD_CACHE_CREDENTIALS = credentials('gradle-ent-cache-credentials')
        POSTGRES_CREDENTIALS = credentials('e2e-postgresql-credentials')
        BUILD_CACHE_USERNAME = "${env.BUILD_CACHE_CREDENTIALS_USR}"
        BUILD_CACHE_PASSWORD = "${env.BUILD_CACHE_CREDENTIALS_PSW}"
        CORDA_ARTIFACTORY_USERNAME = "${env.ARTIFACTORY_CREDENTIALS_USR}"
        CORDA_ARTIFACTORY_PASSWORD = "${env.ARTIFACTORY_CREDENTIALS_PSW}"
        CORDA_DEV_POSTGRES_USER="${env.POSTGRES_CREDENTIALS_USR}"
        CORDA_DEV_POSTGRES_PASSWORD="${env.POSTGRES_CREDENTIALS_PSW}"
        CORDA_DEV_CLUSTER_DB_NAME="${postgresDb}"
        CORDA_USE_CACHE = "corda-remotes"
        KUBECONFIG = credentials("e2e-tests-credentials")
        CORDA_CLI_USER_HOME = "/tmp/corda-cli-home"
        CORDA_GRADLE_SCAN_KEY = credentials('gradle-build-scans-key')
        GRADLE_USER_HOME = "/host_tmp/gradle"
        CORDA_REVISION = "${env.GIT_COMMIT}"
        GRADLE_PERFORMANCE_TUNING = "--max-workers=4 --parallel -Dscan.tag.combined-worker -Si"
    }

    parameters {
        string(name: 'COMMIT_TO_CHECKOUT', defaultValue: '', description: 'Commit ID to check out of SCM - leave blank to take head of current branch')
    }

    options {
        buildDiscarder(logRotator(daysToKeepStr: '14', artifactDaysToKeepStr: '14'))
        timestamps()
    }

    triggers {
        cron('H */2 * * *')
    }

    stages {
        stage('check out') {
            steps {
                script {
                    checkoutGitRevisionOfTriggeringJob(params.COMMIT_TO_CHECKOUT)
                }
            }
        }
        stage('create DBs') {
            environment {
                KUBECONFIG = credentials('e2e-tests-credentials')
            }
            steps {
                script {
                    createPostgresDatabase(postgresPort, postgresHost, postgresDb, postgresCredentialsId)
                }
            }
        }
        stage('build') {
            steps {
                gradlew (':applications:workers:release:combined-worker:assemble')
            }
        } 			
        stage('start combined worker') {       
            environment {
                JAR_PATH = "${env.WORKSPACE}/applications/workers/release/combined-worker/build/bin/corda-combined-worker-5.0.0.0-*.jar"
                JDBC_PATH = "${env.WORKSPACE}/applications/workers/release/combined-worker/drivers"
                REST_TLS_PATH = "${env.WORKSPACE}/applications/workers/release/combined-worker/tls/rest/rest_worker.pfx"
                VM_PARAMETERS = "-Dco.paralleluniverse.fibers.verifyInstrumentation=true"
                LOG4J_PARAMETERS = "-Dlog4j.configurationFile=log4j2-console.xml"
                PROGRAM_PARAMETERS = "--instance-id=0 -mbus.busType=DATABASE -spassphrase=password -ssalt=salt -ddatabase.user=u${postgresDb} -ddatabase.pass=password -ddatabase.jdbc.url=jdbc:postgresql://${postgresHost}:${postgresPort}/${postgresDb} -ddatabase.jdbc.directory=${JDBC_PATH} -rtls.keystore.path=${REST_TLS_PATH} -rtls.keystore.password=mySecretPassword"
                WORKING_DIRECTORY = "${env.WORKSPACE}"
            }
            steps {
                sh '''
                    nohup java ${LOG4J_PARAMETERS} -jar ${VM_PARAMETERS} ${JAR_PATH} ${PROGRAM_PARAMETERS} 2<&1 > workerLogs.txt &
                    export PROCNO=$!
                '''        
            }            
        }
        stage('connect to combined worker') {
            steps {
                script {
                    waitForServiceToBeUp('http://localhost:7004/status', 20, 3)
                }
            }
        }
        stage('smoketests') {
                options {
                    timeout(time: 30, unit: 'MINUTES')
                }
                steps {
                   gradlew('smoketest -PisCombinedWorker=true')
                }
                post {
                    always {
                        junit allowEmptyResults: true, testResults: '**/test-results/**/TEST-*.xml'
                    }
                }
        } 	        
    }
    post {
        always {
            script {      
                    findBuildScans()
                    splunkLogGenerator()
                    getPodLogs("postgres")
                    dropPostgresDB(postgresCredentialsId, env.CORDA_DEV_CLUSTER_DB_NAME)
            }
            archiveArtifacts artifacts: 'forward.txt, workerLogs.txt, podLogs.txt', allowEmptyArchive: true
            sh 'rm -f forward.txt workerLogs.txt podLogs.txt'
        }
        failure {
            sendSlackNotifications("danger", "BUILD FAILURE - Combined Worker E2E Tests", true, "#corda-corda5-build-notifications")
        }
    }
}


def gradleCmd() {
    return isUnix() ? './gradlew' : './gradlew.bat'
}

def gradlew(String... args) {
    def allArgs = args.join(' ')
    sh "${gradleCmd()} ${allArgs} ${GRADLE_PERFORMANCE_TUNING}"
}


//* ********************************************************************
// Everything uder here pulled out of shared library for testing purposes
//* ********************************************************************


/**
* Drop the Postgres database which matches the provided name  
*
* @param postgresDb              The name of the new database to be created
* @param postgresCredentialsId   ID of the credentials used for authentication
*/
void dropPostgresDB(String postgresCredentialsId , String postgresDb) {
    withEnv([
        "DATABASE=${postgresDb}"
    ]) {
        withCredentials([usernamePassword(credentialsId: postgresCredentialsId,
                passwordVariable: 'PGPASSWORD',
                usernameVariable: 'PGUSER')]) {
                    sh 'dropdb -w "${DATABASE}" || true' 
        }
    }
}


/**
* Retrieves the logs of all pods running in the specified k8s namespace and writes them to a file which is then archived
*
* @param namespace      The name of the Kubernetes namespace where the pods are running
*/
void getPodLogs(String namespace) {
    withEnv([
            "NAMESPACE=${namespace}"
    ]) {
        sh '''\
                for pod in $(kubectl -n "${NAMESPACE}" get pods -o name)
                do
                    kubectl -n "${NAMESPACE}" logs --all-containers --prefix $pod 2>&1 >> podLogs.txt
                done
            '''.stripIndent()
        archiveArtifacts artifacts: "podLogs.txt", allowEmptyArchive: true
    }
}

/**
* Ensures that the same commit ID is used in the triggered job as it's caller, 
* in the case where it is triggered from the release branch's CI. This is necessary to prevent an edge case where
* the HEAD revision changes between the start of the calling CI and the downstream job it triggers
*
* @param commitToCheckout       The commit ID to check out which is provided from the calling pipeline
*/
void checkoutGitRevisionOfTriggeringJob(String commitToCheckout) {
    if (commitToCheckout && !env.CHANGE_ID && !env.TAG_NAME) {
        echo "Checking out commit ID from upstream job ${commitToCheckout}"
        withEnv([
            "COMMIT_ID=${commitToCheckout}"
        ]) {
            sh 'git checkout "${COMMIT_ID}"'
        }
    } else {
        if (env.CHANGE_ID) {
            echo "Checking out head revision of ${env.BRANCH_NAME} and merging into ${env.CHANGE_TARGET}"
        } else {
            echo "Checking out head revision of ${env.BRANCH_NAME}"
        }
    }
}

/**
* Connect to the postgres service running in kubuerneties and create a new database insatnce
*
* @param postgresPort            The port used for connecting to Postgres
* @param postgresHost            The host where Postgres is running
* @param postgresDb              The name of the new database to be created
* @param postgresCredentialsId   ID of the credentials used for authentication
*/
void createPostgresDatabase(String postgresPort, String postgresHost, String postgresDb, String postgresCredentialsId) {
    // port forwarding from K8s
    portForwarding('svc/postgres-postgresql', postgresPort, postgresPort, 'postgres')
    // create new DB
    withEnv([
            "PGHOST=${postgresHost}",
            "PGPORT=${postgresPort}",
            "DATABASE=${postgresDb}"
    ]) {
        withCredentials([usernamePassword(credentialsId: postgresCredentialsId,
                passwordVariable: 'PGPASSWORD',
                usernameVariable: 'PGUSER')]) {
                try {
                    sh 'psql --quiet --tuples-only -c \'select \''
                } catch (error) {
                    echo "${error.getMessage()}\nPort forwarding Postgres has not been set up yet, retrying"
                    retry(5) {
                        sleep(time: 5, unit: "SECONDS")
                        sh 'psql --quiet --tuples-only -c \'select \''
                    }
                }
                sh 'createdb -w "${DATABASE}"'
        }
    }
}

void portForwarding(String name, String port, String portMapping, String namespace) {
    withEnv([
            "NAME=$name",
            "PORT=$port",
            "PORT_MAPPING=$portMapping",
            "NAMESPACE=$namespace"
    ]) {
        sh 'nohup kubectl-port-forward-with-reconnect.sh "${NAMESPACE}" "${NAME}" "${PORT}" "${PORT_MAPPING}" >> forward.txt 2>&1 &'
    }
}


/**
* Waits for a service to become available by sending HTTP requests to its endpoint
* and checking the response code.
*
* @param serviceUrl     	    the URL of the service to check
* @param retryIntervalSeconds   the number of seconds to wait between each retry
* @param maxRetries             the maximum number of times to retry before giving up
* @throws error                 if the service does not become available within the specifed number of retries
*/
void waitForServiceToBeUp(String serviceUrl, int maxRetries, int retryIntervalSeconds) {
    int retries = 0
    String status = null
    
    sleep(time: 30, unit: "SECONDS") // wait for 30 seconds before starting to give the service adequate time to start up
    
    while (status != "200" && retries < maxRetries) {
        sleep(time: retryIntervalSeconds, unit: "SECONDS")
        try {
            withEnv([
                "URL=${serviceUrl}"
            ]) {
                status = sh(script: 'curl -s -o /dev/null -w "%{http_code}" "${URL}"', returnStdout: true)
            }
        } catch (error) {
            echo "Failed to connect to ${serviceUrl}, retrying..."
        }
        retries++
    }
    
    if (status != "200") {
        error("Service at ${serviceUrl} failed to start up after ${maxRetries} retries, status code: ${status}")
    } else {
        echo "Service at ${serviceUrl} is up and running."
    }
}
