# Default Kafka properties. Settings in this file are used if no property is specified by the user. If no property is
# specified here, then the Kafka default is used. Note that some set defaults here are the same as those in the enforced
# configuration, as a precaution.

# Common defaults across all consumers and producers
common {
    # Default connection server. Note that this will need overriding in the majority of cases.
    bootstrap.servers = "localhost:9092"
}

# Defaults for all consumers.
consumer = ${common} {
    # This ensures a default where connection with no offset for a consumer group does not result in an exception.
    auto.offset.reset = earliest
    # Ensures that messages from uncommitted transactions are not visible. This is required to meet transactionality
    # requirements on patterns that need it.
    isolation.level = read_committed
    # Force consumers to commit their offsets manually. Again required for transactionality.
    enable.auto.commit = false
    # Retrieve 100 records maximum per poll. Note that poll will return immediately if any records are available, so a
    # batch may contain fewer than 100 records.
    max.poll.records = 100
    # Time to allow between polls on a consumer before a rebalance occurs that removes this consumer's partitions.
    max.poll.interval.ms = 100000
    # Timeout of heartbeats between the consumer and the broker. If no heartbeat is received in this timeframe, a
    # rebalance will occur.
    session.timeout.ms = 6000
    # Frequency of heartbeats between the consumer and the broker. Should be no higher than 1/3 of the session timeout.
    heartbeat.interval.ms = 2000
}

# Defaults for all producers.
producer = ${common} {
    # Ensures that messages are sent to the broker exactly once. Note that some configuration settings must be set to
    # compatible values as a result of this. A ConfigException will be raised if these are set to incompatible values.
    enable.idempotence = true
    # Ensures that messages are not lost due to broker failure at inopportune moments. This forces acknowledgements from
    # all in-sync replicas before continuing, which ensures the message has reached at least one broker.
    acks = all
}

# Roles that particular consumers or producers could be taking. By tying consumers and producers to the roles they are
# performing in the patterns, each can be configured properly to reflect the job they are supposed to do.
roles {
    pubsub {
        consumer = ${consumer} {
            # Pubsub consumers can ignore old messages so choose to start at the end of the stream.
            auto.offset.reset = latest
        }
    }
    compacted {
        consumer = ${consumer}
    }
    durable {
        consumer = ${consumer}
        producer = ${producer}
    }
    stateAndEvent {
        stateConsumer = ${consumer}
        eventConsumer = ${consumer}
        producer = ${producer}
    }
    eventLog {
        consumer = ${consumer}
        producer = ${producer}
    }
    rpcSender {
        consumer = ${consumer} {
            # RPC pattern consumers can ignore old messages so choose to start at the end of the stream.
            auto.offset.reset=latest
        }
        producer = ${producer}
    }
    rpcResponder {
        consumer = ${consumer} {
            # RPC pattern consumers can ignore old messages so choose to start at the end of the stream.
            auto.offset.reset = latest
        }
        producer = ${producer}
    }
    publisher {
        producer = ${producer}
    }
}
